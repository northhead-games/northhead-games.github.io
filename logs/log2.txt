ID log2
TITLE Log 2 - Blazingly Fast<sup>TM</sup> Glyph Rendering
DATE 24 June, 2023

And we're back.  Most of us graduated from university in the past month or so, and I moved, so progress slowed down for a bit, although that's not to say there hasn't been any, it's just that more blog posts weren't our priority given their audience is, generously, about 5 people.  Alex has been working on a physics system, and Yigit's been working on an asset management/serialization system for all of the data we're gonna need{1}.  This week though, I'm going to be talking about my pet project for the past few weeks: Working on a UI and text rendering solution.
NOTE 1 They should have posts about these in the coming weeks if I bother them enough.

As mentioned in <a href="#log1">Log 1</a>, text rasterization is something that I sorted out pretty early on.  However, all that the existing code could do was rasterize predefined text to a texture, and then render that texture to a quad.  This would be fine for static text or buttons, but obviously not for any dynamic content, such as rendering debug info, which happens to be something we really need as we begin to develop tools for working on the game.  Generally my approach when faced with something I don't know much about{2} is to begin by trying to get it working in the simplest way I can think of.  In this case, that was using my existing text rendering code, which renders set text to a bitmap, to create a new bitmap{3} and upload it as a texture to the GPU each frame.  This worked fine, except that it was abysmally slow.
NOTE 2 Most things, but in this case text rendering.
NOTE 3 On the CPU, each frame. I know, I know.

Essentially what I had created was a software rasterizer.  In other words, each frame, I was going over each pixel on the screen (the texture I was writing to was the size of the screen), and determining its color.  While I wasn't doing anything fancy, it's still a really bad idea to do this in software, when the GPU has a whole unit of hardware dedicated to this purpose.  For some reference, my extremely basic text rendering was taking ~5ms, which is nearly a third of our frame budget{4}, running at 1280x720p.  Not good.
NOTE 4 Or a 1/6 if your name starts with "B" and ends in "ethesda".

Scrapping my initial approach, I did some research on text rendering, and found a few common methods.  The more traditional approach is to use what's called a "glyph atlas," where each glyph gets rasterized to a texture at startup, and then the appropriate region of that texture is drawn to quads as needed.  A more modern approach uses a "signed distance function" (SDF), defined for each glyph, to provide properly antialiased glyphs independent of resolution.  While the SDF technique is more flexible, it's significantly more involved than using a glyph atlas, so I opted for the latter.  My initial implementation was very basic, and wrote the geometry for each quad to a vertex buffer, with the position and texture coordinates defined per vertex.  This implementation provided a significant performance increase, but still had some room for improvement.

For one, texture atlases are a little old school, and there are a few problems generally associated with them.  One of these is the simple fact that you can't have textures of different sizes or formats contained within them, since they're part of the same actual texture.  Another is mipmap{5} bleeding, where at lower mipmap levels, the different sub-textures of the atlas will begin to affect one another.  Instead, I decided to use a texture array to store the textures, which means that each glyph gets its own texture.  Then, instead of getting the texture coordinates of a glyph within the atlas, the index of the glyph within the array is used to grab the appropriate texture when rendering.  Because they're different textures, we can size the textures to only be as large as the glyph in question needs to be. Additionally, there's no way for mipmap bleeding to occur anymore.
NOTE 5 Mipmaps are downscaled copies of a texture that the GPU keeps on hand (if enabled) to use if the texture is farther away.

I also was initially drawing the quads the same way I draw all of the 3D geometry: using a vertex buffer and an index buffer.  While this makes sense for rendering 3D meshes, we end up with a lot of redundant data when rendering quads.  For example, for a given quad, we have 4 vertices, which each contain their position, texture coordinate, and character.  This data can be calculated for each vertex in the quad by just knowing the position and character of the quad.  In addition to this redundancy, the vertex and index buffers need to be updated each frame.  Eating up the bus's bandwidth on redundant data is no good, and so I revised my approach.

Instead of using a vertex and index buffer to hold the quad geometry, I got rid of them completely, and instead just tell the GPU to draw 6 vertices{6} for each quad, but don't provide any data per vertex.  Then, in the vertex shader, I use the builtin <span class="code">gl_VertexIndex</span> to calculate which quad is being drawn, and which vertex within that quad is being drawn.  However, the data for each quad still has to exist somewhere on the GPU to be accessible to the vertex shader.  To accomplish this, I use a "shader storage buffer object," or SSBO.  An SSBO is really just a buffer the GPU can read and write from a shader, and can contain really anything we need it to.  It has the advantage of being able to be much larger than uniform buffers and being writeable from the GPU, at the cost of some speed{7}.  The SSBO contains the data for each quad that needs to be drawn, and is persistently host mapped, meaning that it can always be written to from the CPU.

NOTE 6 Six because, now that we've gotten rid of the indices, we need separate vertices for each triangle, and each quad is made up of two triangles.
NOTE 7 Allegedly.

That's more or less it for the text rendering.  It's a shockingly deep topic when you start really drilling down into it, but I've found this quads-and-texture-arrays approach good enough for what we need it for, at least for the time being.  You can see a small UI rendered using this new method below:

IMAGE images/log2_text.png UI Rendering

I've still gotta make an RSS feed for these...

- Oliver
